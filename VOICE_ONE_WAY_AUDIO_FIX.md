# Voice Call One-Way Audio Fix

## üö® Problem

**Symptom**: When User A starts a call, their voice is heard by User B, but User B's voice is NOT heard by User A (one-way audio).

**Root Cause**: User B doesn't have their local audio stream when they receive the offer from User A.

---

## üîç Technical Analysis

### What Was Happening

1. **User A starts call**:
   - Calls `startVoiceCall()`
   - Gets their microphone stream (`getUserMedia()`)
   - Creates peer connection with User B
   - Adds their audio tracks to the connection
   - Sends offer to User B

2. **User B receives offer** (THE PROBLEM):
   - Receives offer via Firebase
   - Creates peer connection
   - **BUT**: User B hasn't called `getUserMedia()` yet!
   - **Result**: No local audio tracks are added to the connection
   - Sends answer back to User A
   - **Outcome**: User A ‚Üí User B works, but User B ‚Üí User A doesn't!

### Why This Happens

In `createPeerConnection()`:

```javascript
// Add local stream tracks
if (localStreamRef.current) {  // ‚ùå This is NULL for User B!
  localStreamRef.current.getTracks().forEach(track => {
    pc.addTrack(track, localStreamRef.current);
  });
}
```

User B's `localStreamRef.current` is `null` because they haven't joined the call yet!

---

## ‚úÖ Solution

**Auto-join when receiving an offer**: If a user receives an offer but isn't in the call yet, automatically join the call first (get microphone access) before creating the peer connection.

### Implementation

```javascript
// Handle offer
if (data.type === 'offer' && data.offer) {
  console.log(`[Voice] Received offer from ${fromUser}`);

  // CRITICAL FIX: If we're not in a call yet, we need to join first
  if (!isInCall || !localStreamRef.current) {
    console.log(`[Voice] Not in call yet, auto-joining to accept offer from ${fromUser}`);
    
    try {
      // Get user media first
      const stream = await getUserMedia();
      if (!stream) {
        console.error(`[Voice] Failed to get user media, cannot accept offer`);
        return;
      }

      // Mark as in call
      setIsInCall(true);
      
      // Update Firebase to add ourselves to participants
      const roomDoc = await getDoc(doc(db, SHARED_ROOM_PATH));
      const existingCall = roomDoc.exists() ? roomDoc.data()?.voiceCall : null;
      const participants = existingCall?.participants || [];
      
      if (!participants.includes(currentLeetCodeUsername)) {
        participants.push(currentLeetCodeUsername);
        await setDoc(doc(db, SHARED_ROOM_PATH), {
          voiceCall: {
            active: true,
            participants: participants,
            startedBy: existingCall?.startedBy || fromUser,
            startedAt: existingCall?.startedAt || Date.now(),
            lastUpdated: Date.now()
          }
        }, { merge: true });
      }
      
      setCallParticipants(participants);
      console.log(`[Voice] Auto-joined call, now have local stream`);
    } catch (err) {
      console.error(`[Voice] Error auto-joining call:`, err);
      return;
    }
  }

  // Now create peer connection (will have local stream)
  let pc = peerConnectionsRef.current.get(fromUser);
  if (!pc) {
    pc = createPeerConnection(fromUser);
    console.log(`[Voice] Created peer connection (has local stream: ${!!localStreamRef.current})`);
  }
  
  // ... rest of offer handling
}
```

---

## üìä Flow Comparison

### Before (One-Way Audio) ‚ùå

```
User A:
1. Click "Call" button
2. getUserMedia() ‚Üí has microphone ‚úÖ
3. Create peer connection
4. Add audio tracks ‚úÖ
5. Send offer to User B

User B:
1. Receive offer
2. Create peer connection
3. Try to add audio tracks ‚Üí NO STREAM ‚ùå
4. Send answer
5. Result: A hears B? NO ‚ùå
```

### After (Two-Way Audio) ‚úÖ

```
User A:
1. Click "Call" button
2. getUserMedia() ‚Üí has microphone ‚úÖ
3. Create peer connection
4. Add audio tracks ‚úÖ
5. Send offer to User B

User B:
1. Receive offer
2. Auto-join call
3. getUserMedia() ‚Üí has microphone ‚úÖ
4. Create peer connection
5. Add audio tracks ‚úÖ
6. Send answer
7. Result: A hears B? YES ‚úÖ
```

---

## üß™ Testing

### Test Case 1: User A Starts Call
1. User A clicks "Call" button
2. User B should automatically join
3. **Expected**: Both users hear each other ‚úÖ

### Test Case 2: Multiple Users
1. User A clicks "Call"
2. User B and User C receive offers
3. Both auto-join
4. **Expected**: All users hear each other ‚úÖ

### Test Case 3: Late Joiner
1. User A and User B are already in call
2. User C clicks "Call" to join
3. **Expected**: User C hears everyone and everyone hears User C ‚úÖ

### Test Case 4: Microphone Permission Denied
1. User A starts call
2. User B receives offer
3. User B denies microphone permission
4. **Expected**: User B doesn't join, error logged ‚úÖ

---

## üêõ Debugging

### Check Console Logs

**User A (Caller):**
```
[Voice] Starting new call with participants: UserA, UserB
[Voice] Initiating connection to UserB
[Voice] Created peer connection for UserB
[Voice] Created offer for UserB
[Voice] Sent offer to UserB via Firebase
```

**User B (Receiver):**
```
[Voice] Received offer from UserA
[Voice] Not in call yet, auto-joining to accept offer from UserA
[Voice] Auto-joined call, now have local stream
[Voice] Created peer connection for UserA (has local stream: true) ‚úÖ
[Voice] Remote description set for UserA
[Voice] Created and set answer for UserA
```

### Verify Local Stream

Add this check in your console:
```javascript
// Check if user has local stream
console.log('Has local stream:', !!localStreamRef.current);
console.log('Local tracks:', localStreamRef.current?.getTracks());
```

**Expected**:
- User A: `true`, `[MediaStreamTrack]`
- User B (after auto-join): `true`, `[MediaStreamTrack]`

---

## üîß Additional Improvements

### 1. Add Visual Feedback

Show when auto-joining:
```javascript
setAppStatus("Joining call...");
// ... auto-join logic
setAppStatus("In call");
```

### 2. Handle Permission Errors

```javascript
if (!stream) {
  setError("Microphone access denied. Cannot join call.");
  return;
}
```

### 3. Retry Logic

If auto-join fails, retry once:
```javascript
let retries = 0;
while (!stream && retries < 2) {
  stream = await getUserMedia();
  retries++;
}
```

---

## ‚úÖ Verification Checklist

- [ ] User A starts call ‚Üí User B auto-joins
- [ ] Both users see each other in participants list
- [ ] User A hears User B ‚úÖ
- [ ] User B hears User A ‚úÖ
- [ ] Console shows "has local stream: true" for both
- [ ] Multiple users can join and all hear each other
- [ ] Microphone permission denial is handled gracefully

---

## üìù Related Issues

### Issue: "NotAllowedError" on Auto-Join

**Cause**: Browser blocks microphone access without user gesture

**Solution**: User must click "Call" button (user gesture) before auto-join

### Issue: Echo/Feedback

**Cause**: User's own audio playing back to them

**Solution**: Already handled - we don't play local stream, only remote streams

### Issue: Audio Cuts Out

**Cause**: ICE connection fails or network issues

**Solution**: Monitor `pc.connectionState` and reconnect if needed

---

## üéØ Impact

**Before**:
- ‚ùå One-way audio (only caller is heard)
- ‚ùå Confusing user experience
- ‚ùå Users had to manually click "Call" to be heard

**After**:
- ‚úÖ Two-way audio (both users hear each other)
- ‚úÖ Seamless auto-join experience
- ‚úÖ Works for multiple participants

---

**Status**: ‚úÖ **FIXED**  
**Date**: December 24, 2025  
**Impact**: Critical - Enables proper two-way voice communication  
**Complexity**: Medium (WebRTC peer connection timing)
